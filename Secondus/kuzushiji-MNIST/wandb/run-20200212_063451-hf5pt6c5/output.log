Scaling input data...
Max value: 255.0
Number of classes in this dataset: 10
One hot encoding targets...
Original input shape: (28, 28, 1)
2020-02-11 22:34:53.537374: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-11 22:34:53.565935: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe2ed3968d0 executing computations on platform Host. Devices:
2020-02-11 22:34:53.565955: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       
_________________________________________________________________
activation_1 (Activation)    (None, 26, 26, 32)        0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 26, 26, 32)        128       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      
_________________________________________________________________
activation_2 (Activation)    (None, 24, 24, 32)        0         
_________________________________________________________________
batch_normalization_2 (Batch (None, 24, 24, 32)        128       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 12, 12, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     
_________________________________________________________________
activation_3 (Activation)    (None, 10, 10, 64)        0         
_________________________________________________________________
batch_normalization_3 (Batch (None, 10, 10, 64)        256       
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928     
_________________________________________________________________
activation_4 (Activation)    (None, 8, 8, 64)          0         
_________________________________________________________________
batch_normalization_4 (Batch (None, 8, 8, 64)          256       
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 4, 4, 64)          0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 4, 4, 128)         73856     
_________________________________________________________________
activation_5 (Activation)    (None, 4, 4, 128)         0         
_________________________________________________________________
batch_normalization_5 (Batch (None, 4, 4, 128)         512       
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 4, 4, 128)         147584    
_________________________________________________________________
activation_6 (Activation)    (None, 4, 4, 128)         0         
_________________________________________________________________
batch_normalization_6 (Batch (None, 4, 4, 128)         512       
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 2, 128)         0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 2, 2, 128)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 512)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 2048)              1050624   
_________________________________________________________________
activation_7 (Activation)    (None, 2048)              0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 2048)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                20490     
_________________________________________________________________
activation_8 (Activation)    (None, 10)                0         
=================================================================
Total params: 1,359,338
Trainable params: 1,358,442
Non-trainable params: 896
_________________________________________________________________
Train on 60000 samples, validate on 10000 samples
Epoch 1/10
 - 115s - loss: 0.5718 - accuracy: 0.8443 - val_loss: 0.6940 - val_accuracy: 0.8116
roc-auc: 0.9973 - roc-auc_val: 0.9863                                                                                                    

Epoch 00001: val_loss improved from inf to 0.69400, saving model to /Users/mitsukakiyohara/GitHub/ATCS_y4_-mitsukakiyohara/Secondus/kuzushiji-MNIST/kmnist_weights.hdf5
Epoch 2/10
 - 112s - loss: 0.1762 - accuracy: 0.9471 - val_loss: 0.3025 - val_accuracy: 0.9267
roc-auc: 0.9996 - roc-auc_val: 0.9958                                                                                                    

Epoch 00002: val_loss improved from 0.69400 to 0.30250, saving model to /Users/mitsukakiyohara/GitHub/ATCS_y4_-mitsukakiyohara/Secondus/kuzushiji-MNIST/kmnist_weights.hdf5
Epoch 3/10
 - 117s - loss: 0.1297 - accuracy: 0.9618 - val_loss: 0.2572 - val_accuracy: 0.9399
roc-auc: 0.9998 - roc-auc_val: 0.9967                                                                                                    

Epoch 00003: val_loss improved from 0.30250 to 0.25723, saving model to /Users/mitsukakiyohara/GitHub/ATCS_y4_-mitsukakiyohara/Secondus/kuzushiji-MNIST/kmnist_weights.hdf5
Epoch 4/10
 - 115s - loss: 0.1136 - accuracy: 0.9673 - val_loss: 0.2114 - val_accuracy: 0.9517
roc-auc: 0.9999 - roc-auc_val: 0.998                                                                                                    

Epoch 00004: val_loss improved from 0.25723 to 0.21138, saving model to /Users/mitsukakiyohara/GitHub/ATCS_y4_-mitsukakiyohara/Secondus/kuzushiji-MNIST/kmnist_weights.hdf5
Epoch 5/10
 - 112s - loss: 0.0974 - accuracy: 0.9717 - val_loss: 0.1818 - val_accuracy: 0.9599
roc-auc: 0.9999 - roc-auc_val: 0.9983                                                                                                    

Epoch 00005: val_loss improved from 0.21138 to 0.18182, saving model to /Users/mitsukakiyohara/GitHub/ATCS_y4_-mitsukakiyohara/Secondus/kuzushiji-MNIST/kmnist_weights.hdf5
Epoch 6/10
 - 115s - loss: 0.0912 - accuracy: 0.9745 - val_loss: 0.1883 - val_accuracy: 0.9579
roc-auc: 0.9999 - roc-auc_val: 0.9983                                                                                                    

Epoch 00006: val_loss did not improve from 0.18182
Epoch 7/10
 - 113s - loss: 0.0824 - accuracy: 0.9770 - val_loss: 0.1703 - val_accuracy: 0.9639
roc-auc: 1.0 - roc-auc_val: 0.9985                                                                                                    

Epoch 00007: val_loss improved from 0.18182 to 0.17033, saving model to /Users/mitsukakiyohara/GitHub/ATCS_y4_-mitsukakiyohara/Secondus/kuzushiji-MNIST/kmnist_weights.hdf5
Epoch 8/10
 - 110s - loss: 0.0796 - accuracy: 0.9778 - val_loss: 0.2138 - val_accuracy: 0.9581
roc-auc: 1.0 - roc-auc_val: 0.9984                                                                                                    

Epoch 00008: val_loss did not improve from 0.17033
Epoch 9/10
 - 110s - loss: 0.0740 - accuracy: 0.9800 - val_loss: 0.2011 - val_accuracy: 0.9606
roc-auc: 1.0 - roc-auc_val: 0.9987                                                                                                    

Epoch 00009: val_loss did not improve from 0.17033
Epoch 10/10
 - 107s - loss: 0.0755 - accuracy: 0.9801 - val_loss: 0.1758 - val_accuracy: 0.9667
roc-auc: 1.0 - roc-auc_val: 0.9988                                                                                                    

Epoch 00010: val_loss did not improve from 0.17033

Test accuracy: 0.96670001745224
